# 깔끔한 데이터

## melt 메서드

> pd.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)

- 지정한 열의 데이터를 모두 행으로 정리해줌

- `id_vars` : list-like. 위치를 그대로 유지할 열 이름들을 지정한다.
- `value_vars` : list-like. 행으로 위치를 변경할 열의 이름을 지정한다.
- `var_name` : str. 행으로 위치를 변경되는 열 이름들을 저장할 variable 열 이름을 지정한다.
- `value_name` : str. value_vars의 값인 value를 저장할 열 이름을 지정한다.
- `col_level` : columns가 MultiIndex인 경우, melt할 level을 지정한다.



```python
pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')
```

- religion 열을 제외한 열들을 행으로 바꾸겠다
- 그 행들의 새로운 열 이름은 income
- 위치 변경한 열의 데이터들의 열 이름은 count
- 이걸 'religion열을 고정하여 피벗' 하였다고 말함



### 선생님 문제

> pew_long 데이터를 이용하여 종교별 평균 수익을 구하라.



```python
tmp = pew_long[~pew_long.income.str.startswith('Do')]
```

- pew_long의 income열에서 Do로 시작하는 행을 삭제한다는 의미
- .str이 들어가야 하나..

```python
incval = [5, 15, 25, 35, 45, 62.5, 87.5, 125, 150]
incdict = {}
for val, inc in zip(incval, tmp.income.unique()):
    incdict[inc] = val
```

- income열의 숫자들을 평균값 리스트로 치환해주는 과정
- 치환 후 새로운 딕셔너리로 만들어준다
- {'<$10k': 5, '$10-20k': 15, '$20-30k': 25, '$30-40k': 35, '$40-50k': 45, '$50-75k': 62.5, '$75-100k': 87.5, '$100-150k': 125, '>150k': 150}

#### zip 함수

```python
l1 = [1, 2, 3]
l2 = list('abd')
for i, j in zip(l1, l2):
    print(i)
    print(j)
    print("====")
```

![image-20200222153145433](C:\Users\NOWNEY\AppData\Roaming\Typora\typora-user-images\image-20200222153145433.png)

-  동일한 개수로 이루어진 자료형을 묶어 주는 역할을 하는 함수

```python
tmp['inc'] = tmp.income.map(lambda x: incdict[x])
tmp['incsum'] = tmp['inc'] * tmp['count']
tmp
```

- tmp 데이터프레임에 inc라는 열을 추가해서 incdict 내의 요소들을 inc라는 열에 넣겠다
- .map : 
  - map(f, iterable)은 함수(f)와 반복 가능한(iterable) 자료형을 입력으로 받는다. map은 입력받은 자료형의 각 요소를 함수 f가 수행한 결과를 묶어서 돌려주는 함수

- incsum이라는 열에는 inc열의 데이터와 count열의 데이터의 곱을 넣어주겠다

```
tmpsum = tmp.groupby('religion')[['count', 'incsum']].sum()
tmpsum
```

- religion별로 묶어서 count 열 합하고 incsum열 합한다

```python
tmpsum['incmean'] = tmpsum['incsum'] / tmpsum['count']
```

- incmean이라는 열을 추가하여 incsum합을 count합으로 나눈 값을 넣는다



### 2개 이상 열 고정하여 melt

```python
billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')
billboard_long
```



```python
mean_billboard = billboard.iloc[:, 1:3]
mean_billboard['meanrate'] = billboard.iloc[:, 5:].mean(1, skipna=True)
```

- week 별로 평균 rate를 구할 건데 mean()함수에 1을 주면 행이 아닌 열의 평균을 구함.
- skipna=True를 주면 NaN 값은 무시하고 계산

```python
grouped = billboard_long.groupby(['artist', 'track'])
grouped[['rating']].mean().reset_index()
```

- 이렇게 계산해도 돼..



---

## 열 이름 관리하기

### 하나의 열이 여러의미를 갖는 경우

#### .split()메서드

```python
variable_split = ebola_long.variable.str.split('_')
variable_split[:5]
```

- 기본적으로 공백을 기준으로 문자열을 자르는데, split메서드에 '_'를 전달하면 그걸 기준으로 분리 가능
- variable_split은 시리즈, 각 시리즈에 저장된 값의 자료형은 리스트

```python
status_values = variable_split.str.get(0) 
country_values = variable_split.str.get(1)
```

- get메서드를 사용하여 0,1번째 인덱스의 데이터를 한 번에 추출

```python
ebola_long['status'] = status_values 
ebola_long['country'] = country_values
```

- 분리한 문자열을 status, country라는 열에 추가



#### concat메서드로 분리한 데이터 바로 추가

```python
variable_split = ebola_long.variable.str.split('_', expand=True) 
variable_split.columns = ['status', 'country'] 
ebola_parsed = pd.concat([ebola_long.iloc[:, :-2], variable_split], axis=1)

ebola_parsed[100:160]
```

- expand=True 옵션 사용 시 시리즈가 아닌 데이터프레임을 리턴한다
- split한 데이터 프레임 칼럼이름 각각 지정
- 마지막 두 열은 중복되니 제외하고 concat
- axis=1로 열추가



```python
ebola_parsed.drop('variable', 1, inplace=True)
```

- axis=1을 1로 줘도 상관 없나봐
- variable이라는 열을 삭제한다는 의미
- inplace는 기존 데이터프레임을 drop 한 후의 데이터 프레임으로 대체하겠다는 의미



## 여러 열을 하나로 정리

#### .pivot_table() 메서드

> 행과 열의 위치를 다시 바꿔 정리해준다

- index 인자에는 위치를 그대로 유지할 열 이름을 지정
  - index로 지정된 열들은 순서대로 계층적 index를 구성한다.
- columns 인자에는 피봇 열들을 구성할 열 이름을 지정
  - columns에는 범주형 열을 지정하며, 그 범주들은 새로운 열이름이 된다.
- values 인자에는 새로운 열의 데이터가 될 열 이름을 지정

```python
weather_tidy = weather_melt.pivot_table(
    index=['id', 'year', 'month', 'day'], 
    columns='element', 
    values='temp'
)
```

- 즉 남은 element와 temp열의 데이터를 피벗할 것
- element 내의 데이터들로 열을 나누고
- temp 내의 데이터들을 아래 데이터로 넣는다

- tmax와 tmin이 모두 결측인 row는 자동으로 제거된다.



## 중복데이터 처리

#### .drop_duplicates()

```
billboard_songs = billboard_songs.drop_duplicates() 
```

- 데이터프레임의 중복 데이터를 제거

근데 중복을 제거한다는게 뭐가 중복되는 것을 어떻게 제거하는 거지

중복을 제거해서 노래 목록을 만든다

```python
billboard_ratings = billboard_long.merge( billboard_songs, on=[
    'year', 'artist', 'track', 'time', 'date.entered']) 
```

- 중복을 제거한 데이터프레임에 아이디를 주어 쉽게 조회, 구분이 가능하게 만들고 다시 merge를 통해 순위 데이터와 합쳐준다



## 대용량 데이터 처리

### 여러개로 나누어진 데이터 불러오기

```python
import os 
import urllib.request

# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.
with open('../data/raw_data_urls.txt', 'r') as data_urls:
    for line, url in enumerate(data_urls):
        if line == 5:
            break 
        fn = url.split('/')[-1].strip()
        fp = os.path.join('', '../data', fn)
        print(url)
        print(fp)
        urllib.request.urlretrieve(url, fp)
```

이건 무슨 코드... 후...

```
import glob 
nyc_taxi_data = glob.glob('../data/fhv_*') 
print(nyc_taxi_data)
taxi1 = pd.read_csv(nyc_taxi_data[0]) 
taxi2 = pd.read_csv(nyc_taxi_data[1]) 
taxi3 = pd.read_csv(nyc_taxi_data[2]) 
taxi4 = pd.read_csv(nyc_taxi_data[3]) 
taxi5 = pd.read_csv(nyc_taxi_data[4])
```

- 다 불러왔으면 .concat으로 합쳐주면 된다



### for문으로 하는 건 잘 모르겠다

담에 보자....



+++ 선생님 파일에 plot 그리는것도 확인...